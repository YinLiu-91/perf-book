---
typora-root-url: ..\..\img
---

## Measuring Performance In Production

当应用程序在共享基础架构上运行时（通常在公共云中），通常会有来自其他客户的其他工作负载在同一服务器上运行。随着虚拟化和容器等技术变得越来越流行，公共云提供商试图充分利用其服务器的容量。不幸的是，它为在这样的环境中测量性能创造了额外的障碍。与相邻进程共享资源会以不可预知的方式影响性能测量。

通过在实验室中重新创建生产工作负载来分析它们可能很棘手。有时不可能为“内部”性能测试综合准确的行为。这就是为什么越来越多的云提供商和超大规模企业选择直接在生产系统上分析和监控性能 [@GoogleWideProfiling]。在“没有其他参与者”的情况下衡量性能可能无法反映真实世界的情况。实施在实验室环境中表现良好但在生产环境中表现不佳的代码优化将是浪费时间。话虽如此，它并没有消除持续“内部”测试以及早发现性能问题的需要。并非所有性能回归都可以在实验室中捕获，但工程师应该设计代表真实场景的性能基准。

大型服务提供商实施监测用户设备性能的遥测系统已成为一种趋势。一个这样的例子是 Netflix Icarus[^1] 遥测服务，它在遍布全球的数千种不同设备上运行。这样的遥测系统有助于 Netflix 了解真实用户如何看待 Netflix 的应用程序性能。它允许工程师分析从许多设备收集的数据，并找到其他方式无法找到的问题。此类数据允许就优化工作的重点做出更明智的决策。

监控生产部署的一个重要警告是测量开销。由于任何类型的监控都会影响正在运行的服务的性能，因此建议仅使用轻量级分析方法。根据 [@GoogleWideProfiling]：“要对服务于真实流量的数据中心机器进行持续分析，极低的开销至关重要”。通常，可接受的总开销被认为低于 1%。通过限制配置文件的机器集以及使用更长的时间间隔，可以减少性能监控开销。

在这样的生产环境中衡量性能意味着我们必须接受其嘈杂的性质并使用统计方法来分析结果。在 [@liu2019largescale] 中可以找到像 LinkedIn 这样的大公司如何在生产环境中的 A/B 测试中使用统计方法来衡量和比较基于分位数的指标（例如，第 90 个百分位的页面加载时间）的一个很好的例子。

[^1]: Presented at CMG 2019, [https://www.youtube.com/watch?v=4RG2DUK03_0](https://www.youtube.com/watch?v=4RG2DUK03_0).
